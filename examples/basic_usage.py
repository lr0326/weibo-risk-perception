"""
åŸºç¡€ä½¿ç”¨ç¤ºä¾‹
"""

import sys
import os

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


def example_data_collection():
    """æ•°æ®é‡‡é›†ç¤ºä¾‹"""
    print("="*50)
    print("ç¤ºä¾‹1: æ•°æ®é‡‡é›†")
    print("="*50)

    from src.data_collection.weibo_collector import MockWeiboDataGenerator

    # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå™¨
    generator = MockWeiboDataGenerator()
    df = generator.generate_mock_data(100)

    print(f"ç”Ÿæˆ {len(df)} æ¡æ¨¡æ‹Ÿå¾®åšæ•°æ®")
    print(f"å­—æ®µ: {list(df.columns)}")
    print(f"\nç¤ºä¾‹æ•°æ®:")
    print(df.head())


def example_sentiment_analysis():
    """æƒ…æ„Ÿåˆ†æç¤ºä¾‹"""
    print("\n" + "="*50)
    print("ç¤ºä¾‹2: æƒ…æ„Ÿåˆ†æ")
    print("="*50)

    from src.analysis.sentiment_analyzer import SentimentAnalyzer

    analyzer = SentimentAnalyzer(model_type="snownlp")

    texts = [
        "ä»Šå¤©å¿ƒæƒ…çœŸå¥½ï¼Œå¤©æ°”ä¹Ÿå¾ˆæ£’ï¼",
        "è¿™ä¸ªæ”¿ç­–å¤ªè®©äººå¤±æœ›äº†",
        "æ˜å¤©è¦å¼€ä¼šè®¨è®ºé¡¹ç›®è¿›å±•",
        "ç–«æƒ…å½¢åŠ¿ä¸¥å³»ï¼Œå¤§å®¶éƒ½å¾ˆæ‹…å¿ƒ",
        "éå¸¸æ»¡æ„è¿™æ¬¡çš„æœåŠ¡ä½“éªŒ"
    ]

    for text in texts:
        result = analyzer.analyze_sentiment(text)
        print(f"\næ–‡æœ¬: {text}")
        print(f"  ææ€§: {result.polarity} (å¾—åˆ†: {result.polarity_score:.3f})")
        print(f"  æƒ…ç»ª: {result.emotion}")
        print(f"  å¼ºåº¦: {result.intensity:.3f}")


def example_risk_assessment():
    """é£é™©è¯„ä¼°ç¤ºä¾‹"""
    print("\n" + "="*50)
    print("ç¤ºä¾‹3: é£é™©è¯„ä¼°")
    print("="*50)

    import pandas as pd
    from src.analysis.risk_perception import RiskPerceptionAnalyzer

    analyzer = RiskPerceptionAnalyzer()

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = pd.DataFrame({
        "content": [
            "ç–«æƒ…å½¢åŠ¿ä¸¥å³»ï¼Œå¤§å®¶ä¸€å®šè¦åšå¥½é˜²æŠ¤",
            "ç»æµä¸‹è¡Œå‹åŠ›å¤§ï¼Œå¾ˆå¤šä¼ä¸šé¢ä¸´å›°éš¾",
            "å¯¹è¿™ä¸ªæ”¿ç­–å¾ˆæ‹…å¿ƒï¼Œä¸çŸ¥é“ä¼šæœ‰ä»€ä¹ˆå½±å“",
            "ä»Šå¤©å¤©æ°”ä¸é”™ï¼Œå‡ºå»é€›äº†é€›è¡—",
            "å¤ªç”Ÿæ°”äº†ï¼Œè¿™ç§äº‹æƒ…æ€ä¹ˆèƒ½å‘ç”Ÿ",
            "ç—…æ¯’ä¼ æ’­é€Ÿåº¦å¤ªå¿«äº†ï¼Œå¥½å®³æ€•"
        ],
        "created_at": pd.date_range("2024-01-01", periods=6, freq="H"),
        "reposts_count": [100, 50, 200, 10, 80, 150]
    })

    # è¯„ä¼°é£é™©
    result = analyzer.analyze_risk(test_data)

    print(f"ç»¼åˆé£é™©å¾—åˆ†: {result.overall_score:.1f}")
    print(f"é£é™©ç­‰çº§: {result.risk_level.value}")
    print(f"è¶‹åŠ¿: {result.trend}")

    print("\nç»´åº¦å¾—åˆ†:")
    for dim, score in result.dimension_scores.items():
        print(f"  {dim}: {score:.1f}")

    print("\né¢„è­¦ä¿¡æ¯:")
    for warning in result.warnings:
        print(f"  {warning}")


def example_text_processing():
    """æ–‡æœ¬å¤„ç†ç¤ºä¾‹"""
    print("\n" + "="*50)
    print("ç¤ºä¾‹4: æ–‡æœ¬å¤„ç†")
    print("="*50)

    from src.preprocessing.text_cleaner import TextCleaner

    cleaner = TextCleaner()

    texts = [
        "ä»Šå¤©å¤©æ°”çœŸå¥½ï¼#åŒ—äº¬ç”Ÿæ´»# @å°æ˜ https://example.com [å¼€å¿ƒ]",
        "ç–«æƒ…é˜²æ§æ”¿ç­–è°ƒæ•´äº†ï¼Œå¤§å®¶æ€ä¹ˆçœ‹ï¼ŸğŸ¤”",
        "è½¬å‘å¾®åšï¼šç»æµå½¢åŠ¿åˆ†æ..."
    ]

    for text in texts:
        cleaned = cleaner.clean(text)
        tokens = cleaner.tokenize(text)

        print(f"\nåŸæ–‡: {text}")
        print(f"æ¸…æ´—: {cleaned}")
        print(f"åˆ†è¯: {' / '.join(tokens)}")


def example_full_pipeline():
    """å®Œæ•´æµç¨‹ç¤ºä¾‹"""
    print("\n" + "="*50)
    print("ç¤ºä¾‹5: å®Œæ•´åˆ†ææµç¨‹")
    print("="*50)

    from src.pipeline import RiskPerceptionPipeline

    # åˆå§‹åŒ–æµæ°´çº¿
    pipeline = RiskPerceptionPipeline()

    # è¿è¡Œå®Œæ•´åˆ†æï¼ˆä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼‰
    results = pipeline.run_full_analysis(
        keywords="ç¤¾ä¼šçƒ­ç‚¹",
        count=30,
        pages=1,
        use_mock=True
    )

    print("\nåˆ†æç»“æœ:")
    print(f"  æ ·æœ¬é‡: {results.get('sample_size', 0)}")
    print(f"  é£é™©ç­‰çº§: {results.get('risk_level', '-')}")
    print(f"  é£é™©å¾—åˆ†: {results.get('risk_score', 0):.1f}")


def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("å¾®åšèˆ†æƒ…é£é™©æ„ŸçŸ¥ç³»ç»Ÿ - ä½¿ç”¨ç¤ºä¾‹\n")

    example_data_collection()
    example_sentiment_analysis()
    example_risk_assessment()
    example_text_processing()
    example_full_pipeline()

    print("\n" + "="*50)
    print("æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆ!")
    print("="*50)


if __name__ == "__main__":
    main()

